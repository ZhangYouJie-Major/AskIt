"""
RAG æœåŠ¡ - åŸºäº LangChain 1.x
"""
from typing import List, Dict, Any, Optional
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from loguru import logger

from app.core.config import settings
from app.services.vector_store import vector_store


class RAGService:
    """RAG é—®ç­”æœåŠ¡ - LangChain 1.x"""

    def __init__(self):
        # åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=settings.llm_model,
            openai_api_key=settings.openai_api_key,
            openai_api_base=settings.openai_base_url,
            temperature=0.7,
        )

        # åˆå§‹åŒ– Embeddings
        self.embeddings = OpenAIEmbeddings(
            model=settings.embedding_model,
            openai_api_key=settings.openai_api_key,
            openai_api_base=settings.openai_base_url,
        )

    async def query(
        self,
        question: str,
        department_id: int,
        history: Optional[List[Dict[str, str]]] = None,
        top_k: int = 5,
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œ RAG æŸ¥è¯¢

        Args:
            question: ç”¨æˆ·é—®é¢˜
            department_id: éƒ¨é—¨IDï¼ˆç”¨äºæƒé™è¿‡æ»¤ï¼‰
            history: å¯¹è¯å†å²
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡

        Returns:
            åŒ…å«ç­”æ¡ˆå’Œæ¥æºæ–‡æ¡£çš„å­—å…¸
        """
        logger.info("=" * 60)
        logger.info("ğŸ“‹ RAG æŸ¥è¯¢å¼€å§‹")
        logger.info(f"ğŸ‘¤ ç”¨æˆ·é—®é¢˜: {question}")
        logger.info(f"ğŸ¢ éƒ¨é—¨ID: {department_id}")
        logger.info(f"ğŸ“Š è¿”å›æ–‡æ¡£æ•°: {top_k}")

        # 1. å¯¹é—®é¢˜è¿›è¡Œå‘é‡åŒ–
        logger.info("ğŸ”„ æ­¥éª¤ 1/6: é—®é¢˜å‘é‡åŒ–...")
        query_vector = await self.embeddings.aembed_query(question)
        logger.info(f"âœ… å‘é‡åŒ–å®Œæˆï¼Œç»´åº¦: {len(query_vector)}")

        # 2. å‘é‡æœç´¢
        logger.info("ğŸ” æ­¥éª¤ 2/6: å‘é‡æœç´¢...")
        search_results = await vector_store.search(
            vector=query_vector,
            limit=top_k,
            department_id=department_id,
        )
        logger.info(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£")

        # æ‰“å°æœç´¢ç»“æœè¯¦æƒ…
        if search_results:
            logger.info("ğŸ“„ æœç´¢ç»“æœè¯¦æƒ…:")
            for i, r in enumerate(search_results, 1):
                score = r.get("score", 0)
                filename = r["payload"].get("filename", "æœªçŸ¥æ–‡ä»¶")
                content = r["payload"].get("content", "")
                logger.info(f"  [{i}] {filename} (ç›¸ä¼¼åº¦: {score:.4f})")
                logger.info(f"      å†…å®¹é¢„è§ˆ: {content[:100]}...")
        else:
            logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³æ–‡æ¡£")

        # 3. æ„å»ºä¸Šä¸‹æ–‡
        logger.info("ğŸ“ æ­¥éª¤ 3/6: æ„å»ºä¸Šä¸‹æ–‡...")
        context = self._build_context(search_results)
        logger.info(f"âœ… ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆï¼Œé•¿åº¦: {len(context)} å­—ç¬¦")
        logger.debug(f"ğŸ“– ä¸Šä¸‹æ–‡å†…å®¹:\n{context}")

        # 4. æ„å»ºå†å²ä¸Šä¸‹æ–‡
        logger.info("ğŸ’¬ æ­¥éª¤ 4/6: æ„å»ºå†å²ä¸Šä¸‹æ–‡...")
        history_context = self._build_history_context(history or [])
        if history_context:
            logger.info(f"âœ… å†å²ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆï¼Œè½®æ•°: {len(history or [])}")
            logger.debug(f"ğŸ“– å†å²å†…å®¹:\n{history_context}")
        else:
            logger.info("âœ… æ— å¯¹è¯å†å²")

        # 5. æ„å»ºæç¤ºè¯
        logger.info("âœï¸  æ­¥éª¤ 5/6: æ„å»ºæç¤ºè¯...")
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šçŸ¥è¯†åº“åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

{history_context}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

æ³¨æ„äº‹é¡¹ï¼š
1. å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·åŸºäºä¸Šä¸‹æ–‡å›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®å‘ŠçŸ¥ç”¨æˆ·
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€ä¸“ä¸š
4. å¯ä»¥å¼•ç”¨å…·ä½“çš„æ–‡æ¡£å†…å®¹

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š"""
        logger.info(f"âœ… æç¤ºè¯æ„å»ºå®Œæˆï¼Œé•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.debug(f"ğŸ“– å®Œæ•´æç¤ºè¯:\n{prompt}")

        # 6. ç”Ÿæˆå›ç­”
        logger.info("ğŸ¤– æ­¥éª¤ 6/6: è°ƒç”¨ LLM ç”Ÿæˆå›ç­”...")
        response = await self.llm.ainvoke(prompt)
        logger.info("âœ… LLM å›ç­”ç”Ÿæˆå®Œæˆ")
        logger.info(f"ğŸ’¡ å›ç­”å†…å®¹: {response.content}")
        logger.info("=" * 60)

        return {
            "answer": response.content,
            "sources": [
                {
                    "document_id": r["payload"]["document_id"],
                    "chunk_id": r["payload"]["chunk_id"],
                    "filename": r["payload"]["filename"],
                    "score": r["score"],
                }
                for r in search_results
            ],
        }

    def _build_context(self, search_results: List[Dict[str, Any]]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
        if not search_results:
            return "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
        contexts = []
        for r in search_results:
            content = r["payload"].get("content", "")
            filename = r["payload"].get("filename", "")
            contexts.append(f"ã€{filename}ã€‘\n{content}")
        return "\n\n".join(contexts)

    def _build_history_context(self, history: List[Dict[str, str]]) -> str:
        """æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡"""
        if not history:
            return ""
        lines = ["å¯¹è¯å†å²ï¼š"]
        for msg in history:
            role = "ç”¨æˆ·" if msg.get("role") == "user" else "åŠ©æ‰‹"
            content = msg.get("content", "")
            lines.append(f"{role}ï¼š{content}")
        return "\n".join(lines)


# å…¨å±€å®ä¾‹
rag_service = RAGService()
